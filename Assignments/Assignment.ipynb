{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732a20b2",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment you are tasked to fill this notebook by answering the questions, sometimes you will find questions that require you to type, you can do that by inserting a Markdown cell below the question and type your answer in it.\n",
    "\n",
    "## Goal:\n",
    "The goals of this assignment are:\n",
    "- Implement, debug and visualize multivariate linear regression to nonlinear data\n",
    "- Get introduced to the concepts of overfitting and underfitting\n",
    "- Implementing linear regression with regualrization and understanding the importance of train\\test errors\n",
    "\n",
    "Throughout this assignment you will be using the `Assignment_Data.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278aa23b",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18148948",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Assignment_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d586e",
   "metadata": {},
   "source": [
    "## Understand and Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0029bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d5dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf09d53",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Make a scatter plot to visualize the data, what are your comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755ebe3",
   "metadata": {},
   "source": [
    "As explained in class, linear regression might not be directly suitable for nonlinear data.\n",
    "However, by doing feature expansion we can still use linear regression techniques to fit nonlinear data. As a result, you will be able to fit the data using different degrees polynomials, e.g. a degree two polynomial (which is a linear combination of $1, x$ and $x^2$), or a degree three polynomial (which is a linear combination of $1, x, x^2$ and $x^3$), etc...\n",
    "\n",
    "Higher degree polynomials are more expensive to compute and to fit, but can capture finer details in the data, which results in more expressive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc30424",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data['X'])\n",
    "y = np.array(data['Y'])\n",
    "print(f'Shape of x {x.shape}')\n",
    "print(f'Shape of y {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b925ee",
   "metadata": {},
   "source": [
    "## Process the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5334993f",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Complete the following function `build_poly()` which is a function that takes the 1D array x as input along with an integer value degree and outputs a 2D array phi that expands x into a polynomial with the associated degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"Polynomial expansion of x with the given degree\"\"\"\n",
    "    # write your code in between these two lines\n",
    "    # ***************************************************\n",
    "\n",
    "    # ***************************************************\n",
    "    \n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ebe1f",
   "metadata": {},
   "source": [
    "The function `plot_fitted_curve()` is used to plot the learned curve on top of the data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitted_curve(y, x, weights, degree, ax):\n",
    "    \"\"\"plot the fitted curve.\"\"\"\n",
    "    ax.scatter(x, y, color='b', s=12, facecolors='none', edgecolors='r')\n",
    "    xvals = np.arange(min(x) - 0.1, max(x) + 0.1, 0.1)\n",
    "    tx = build_poly(xvals, degree)\n",
    "    f = tx.dot(weights)\n",
    "    ax.plot(xvals, f)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_title(\"Polynomial degree \" + str(degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d10cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToRescaled(x, mean=None, std=None):\n",
    "    if mean is None:\n",
    "        mean = np.mean(x)\n",
    "    if std is None:\n",
    "        std = np.std(x)\n",
    "    x_ = (x - mean) / std\n",
    "    return x_, mean, std\n",
    "    \n",
    "def FromRescaled(x_, mean, std):\n",
    "    x = x_ * std + mean \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280ce19",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Use the function ToRescaled() to rescale the values of X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a297a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_ = ...\n",
    "# y_ = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e0a16",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f2f63",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Complete the function `polynomial_regression_direct()` to implement the direct method of solving linear regression for polynomials of degree 1, 3, 7, and 12. Use `plot_fitted_curve()` to plot the results, and show the MSE for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression_direct():\n",
    "    \"\"\"Constructing the polynomial basis function expansion of the data,\n",
    "       and then running least squares regression.\"\"\"\n",
    "    # define parameters\n",
    "    degrees = [1, 3, 7, 12]\n",
    "    \n",
    "    # define the structure of the figure\n",
    "    num_row = 2\n",
    "    num_col = 2\n",
    "    f, axs = plt.subplots(num_row, num_col)\n",
    "\n",
    "    for ind, degree in enumerate(degrees):\n",
    "        # write your code in between these two lines\n",
    "        # ***************************************************\n",
    "\n",
    "        # ***************************************************\n",
    "        print(\"Processing {i}th experiment, degree={d}, mse={mse}\".format(\n",
    "              i=ind + 1, d=degree, mse=mse))\n",
    "        # plot fit\n",
    "        plot_fitted_curve(\n",
    "            y_, x_, weights, degree, axs[ind // num_col][ind % num_col])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b6a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "polynomial_regression_direct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f6bd1",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Comment on the values of the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba8a58",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Complete the function `polynomial_regression_GradientDescent()` to do the same as Question 4 but by using gradient descent this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression_GradientDescent():\n",
    "    degrees = [1, 3, 7, 12]\n",
    "    T = [10000, 10000, 100000, 10000000]   # number of times steps\n",
    "    alpha = [1.0, 0.01, 0.001, 0.00001]  # learning parameter\n",
    "    num_row = 2\n",
    "    num_col = 2\n",
    "    f, axs = plt.subplots(num_row, num_col)\n",
    "    for ind, degree in enumerate(degrees):\n",
    "        # write your code in between these two lines\n",
    "        # ***************************************************\n",
    "\n",
    "        # ***************************************************\n",
    "        theta = np.random.rand(M)\n",
    "        for t in range(T[ind]):\n",
    "            # write your code in between these two lines\n",
    "            # ***************************************************\n",
    "\n",
    "            # ***************************************************\n",
    "            \n",
    "        print(\"Processing {i}th experiment, degree={d}, mse={loss}\".format(\n",
    "                  i=ind + 1, d=degree, loss=J))\n",
    "        plot_fitted_curve(\n",
    "            y_, x_, theta, degree, axs[ind // num_col][ind % num_col])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79098f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_regression_GradientDescent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7076c2",
   "metadata": {},
   "source": [
    "## Train/Test Split and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57e829",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Let us show the train and test splits for various polynomial degrees. First of all, please fill in the function `split_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing, this function returns four arrays\n",
    "    x & y for training, and x & y for testing\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    data_size = len(y)\n",
    "    # write your code in between these two lines\n",
    "    # ***************************************************\n",
    "   \n",
    "    # ***************************************************\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d05d1",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "Fill the `train_test_split_demo()` function that splits the data by using the function `split_data()` and then uses the direct method to solve the polynomial regression and prints the split ratio, polynomial degree, the training error, and the testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26609e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"polynomial regression with different split ratios and different degrees.\"\"\"\n",
    "    # write your code in between these two lines\n",
    "    # ***************************************************\n",
    "\n",
    "    # ***************************************************\n",
    "    \n",
    "    print(\"proportion={p}, degree={d}, Training MSE={tr:.3f}, Testing MSE={te:.3f}\".format(\n",
    "          p=ratio, d=degree, tr=mse_tr[0,0], te=mse_te[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0a36f",
   "metadata": {},
   "source": [
    "Run the cell below to test your functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 6\n",
    "degrees = [1, 3, 7, 12]\n",
    "split_ratios = [0.9, 0.5, 0.1]\n",
    "\n",
    "for split_ratio in split_ratios:\n",
    "    for degree in degrees:\n",
    "        train_test_split_demo(x_, y_, degree, split_ratio, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27dbec",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "Do the training and testing MSE make sense for diffrent ratios? Why? Which one is the best? <br>\n",
    "What if instead of having 50 samples you had 5000, which split might be best? <br>\n",
    "Comment on the high testing MSE for 10% split especially with high degree polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95a5e0",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba09654",
   "metadata": {},
   "source": [
    "The previous exercise shows overfitting when using complex models. Here we will try to correct that by using Ridge Regression. Ridge Regression is very similar to linear regression, the only difference is that we will add to the cost function a regularization term that penalizes high weight values.\n",
    "$$J(\\theta) = \\frac{1}{2N}\n",
    "\\left[\\sum_{i=1}^N \\left(h_\\theta(x^{(i)}) - y^{(i)} \\right)^2 + \\lambda\\sum_{j=1}^D {\\theta_j}^2\\right]$$\n",
    "With $D$ being the degree of the polynomials used, and $\\lambda>0$ the penalty parameter. <br>\n",
    "Doing that is useful to prevent overfitting when the model used is too complex. <br>\n",
    "It turns out that Ridge Regression also has closed form solution which is the following:\n",
    "$$\\theta^*_{ridge} = \\left(X^T X + \\lambda \\tilde I\\right)^{-1} X^T y $$\n",
    "Where $\\tilde I$ is the diagonal matrix of dimension $D+1$ with $\\{0,1\\cdots 1\\}$ on the diagonal. <br>\n",
    "In what follows we will be working with polynomials of degree 7 only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500047bc",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "Complete the function `ridge_regression()` that takes the output y, the feature matrix tx, and the penalty parameter $\\lambda$ to compute the ridge regression solution weights and the corresponding MSE. You can test the function by setting $\\lambda=0$ and check that you should get the same solution as regular multivariate linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    # write your code in between these two lines\n",
    "    # ***************************************************\n",
    "\n",
    "    # ***************************************************\n",
    "    return w,mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11812ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ridge_regression():\n",
    "    degree = 7\n",
    "    phi = build_poly(x_, degree)\n",
    "    weights, mse = ridge_regression(y_, phi, 0)\n",
    "    print(\"degree={d}, mse={mse}\".format(d=degree, mse=mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ridge_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdecfdbc",
   "metadata": {},
   "source": [
    "The function `plot_train_test()` is used to plot the train and test errors for different values of $\\lambda' = \\frac{\\lambda}{2N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ad935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test(train_errors, test_errors, lambdas, degree):\n",
    "    \"\"\"\n",
    "    train_errors, test_errors and lambdas should be list (of the same size) the respective train error and test error for a given lambda,\n",
    "    * lambda[0] = 1\n",
    "    * train_errors[0] = RMSE of a ridge regression on the train set\n",
    "    * test_errors[0] = RMSE of the parameter found by ridge regression applied on the test set\n",
    "    \n",
    "    degree is just used for the title of the plot.\n",
    "    \"\"\"\n",
    "    plt.semilogx(lambdas, train_errors, color='b', marker='*', label=\"Train error\")\n",
    "    plt.semilogx(lambdas, test_errors, color='r', marker='*', label=\"Test error\")\n",
    "    plt.xlabel(\"$\\lambda$'\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(\"Ridge regression for polynomial degree \" + str(degree))\n",
    "    leg = plt.legend(loc=1, shadow=True)\n",
    "    leg.draw_frame(False)\n",
    "    plt.savefig(\"ridge_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc49b6",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "complete the function `ridge_regression_demo()` to run ridge regression with different values of $\\lambda'$, run the cell below that to test the function and generate the plot, and comment on the generated plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "    phi = build_poly(x, degree)\n",
    "    train_x, train_y, test_x, test_y = split_data(phi, y, ratio, seed=seed)\n",
    "\n",
    "    mse_tr = []\n",
    "    mse_te = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        # write your code in between these two lines\n",
    "        # ***************************************************\n",
    "\n",
    "        # ***************************************************\n",
    "        print(\"proportion={p}, degree={d}, lambda={l:.3f}, Training MSE={tr:.3f}, Testing MSE={te:.3f}\".format(\n",
    "               p=ratio, d=degree, l=lambda_, tr=mse_tr[ind], te=mse_te[ind]))\n",
    "        \n",
    "    # Plot the obtained results\n",
    "    plot_train_test(mse_tr, mse_te, lambdas, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8b962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 56\n",
    "degree = 7\n",
    "split_ratio = 0.5\n",
    "ridge_regression_demo(x, y, degree, split_ratio, seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
